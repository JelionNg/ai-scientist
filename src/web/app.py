import gradio as gr
from typing import Dict, Any
from src.agents.types import ResearchStage, AgentType
from loguru import logger
import asyncio

class WebUI:
    def __init__(self, supervisor):
        self.supervisor = supervisor
        self.current_text = []
        self.current_state = None  # ç”¨äºå­˜å‚¨å½“å‰çŠ¶æ€
        self.total_tokens = 0
        self.expected_tokens = 1000  # é¢„ä¼°tokenæ•°
        self.should_stop = False  # æ·»åŠ åœæ­¢æ ‡å¿—
        self.is_generating = False  # ç”ŸæˆçŠ¶æ€æ ‡å¿—
        self._generator_instance = None  # å­˜å‚¨å½“å‰ç”Ÿæˆå™¨å®ä¾‹
        self.generation_id = 0  # æ·»åŠ ç”ŸæˆIDæ¥è·Ÿè¸ªæ¯æ¬¡ç”Ÿæˆ
        
    def format_hypothesis(self, hypothesis):
        """æ ¼å¼åŒ–å‡è®¾ä¸ºMarkdownæ ¼å¼"""
        # è·å–å‡è®¾å†…å®¹
        content = hypothesis.get("content", {})
        
        # æå–å„ä¸ªéƒ¨åˆ†
        description = content.get("description", "æœªæä¾›")
        theoretical_basis = content.get("theoretical_basis", "æœªæä¾›")
        verification_method = content.get("verification_method", "æœªæä¾›")
        influencing_factors = content.get("influencing_factors", "æœªæä¾›")
        
        # æ„å»ºMarkdownæ ¼å¼çš„å‡è®¾
        markdown = f"""#### ğŸ”¬ ç ”ç©¶å‡è®¾ {hypothesis.get('id', 'unknown')}

ğŸ“Œ å‡è®¾æè¿°
{description}

ğŸ“š ç†è®ºä¾æ®
{theoretical_basis}

ğŸ” éªŒè¯æ–¹æ³•
{verification_method}

âš¡ å½±å“å› ç´ 
{influencing_factors}

---
"""
        return markdown

    def format_final_report(self, result, question, background):
        """æ ¼å¼åŒ–æœ€ç»ˆç ”ç©¶æŠ¥å‘Š"""
        report = f"""# ğŸ“‘ ç ”ç©¶æŠ¥å‘Š

## ğŸ“Œ ç ”ç©¶æ¦‚è¿°

**ç ”ç©¶é—®é¢˜**
{question}

**ç ”ç©¶èƒŒæ™¯**
{background or 'æœªæä¾›èƒŒæ™¯ä¿¡æ¯'}

## ğŸ”¬ ç ”ç©¶å‡è®¾

"""
        # æ·»åŠ å‡è®¾
        for hypothesis in result.get("hypotheses", []):
            report += self.format_hypothesis(hypothesis)
            
        # æ·»åŠ è¯„ä¼°ç»“æœ
        if result.get("evaluation"):
            report += "\n## ğŸ“Š è¯„ä¼°ç»“æœ\n\n"
            report += str(result["evaluation"])
        
        # æ·»åŠ å®éªŒè®¾è®¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if result.get("experiments"):
            report += "\n## ğŸ§ª å®éªŒè®¾è®¡\n\n"
            report += str(result["experiments"])
        
        # æ·»åŠ ç»“è®ºå’Œå»ºè®®
        report += "\n## ğŸ’¡ ç»“è®ºä¸å»ºè®®\n\n"
        report += "1. å»ºè®®ä¼˜å…ˆéªŒè¯æœ€å…·åˆ›æ–°æ€§å’Œå¯è¡Œæ€§çš„å‡è®¾\n"
        report += "2. å®éªŒè®¾è®¡åº”æ³¨æ„æ§åˆ¶å˜é‡\n"
        report += "3. å»ºè®®è¿›è¡Œå°è§„æ¨¡é¢„å®éªŒéªŒè¯æ–¹æ¡ˆå¯è¡Œæ€§\n"
        
        return report

    async def handle_chunk(self, data: Dict[str, Any]):
        """ç›´æ¥å¤„ç†chunkçš„å›è°ƒæ–¹æ³•"""
        if data.get("status") == "generating":
            if "chunk" in data:
                self.current_text.append(data["chunk"])
                current_content = "".join(self.current_text)
                
                self.current_state = self._get_update_state(
                    progress="### ğŸ“Š ç ”ç©¶è¿›åº¦\næ­£åœ¨ç”Ÿæˆå‡è®¾...",
                    hypothesis_status="ğŸ”„ æ­£åœ¨ç”Ÿæˆ...",
                    hypothesis_output=f"```\n{current_content}\n```"
                )
                return self.current_state
                
            elif "hypotheses" in data:
                hypotheses = data["hypotheses"]
                if hypotheses:
                    hypotheses_text = "## ğŸ§¬ æ­£åœ¨ç”Ÿæˆç ”ç©¶å‡è®¾...\n\n"
                    for hypothesis in hypotheses:
                        hypotheses_text += self.format_hypothesis(hypothesis)
                    
                    self.current_state = self._get_update_state(
                        progress="### ğŸ“Š ç ”ç©¶è¿›åº¦\næ­£åœ¨ç”Ÿæˆå‡è®¾...",
                        hypothesis_status="ğŸ”„ æ­£åœ¨ç”Ÿæˆ...",
                        hypothesis_output=hypotheses_text
                    )
                    return self.current_state

    async def process_research(self, question: str, background: str):
        """å¤„ç†ç ”ç©¶è¯·æ±‚ï¼Œæ”¯æŒæµå¼è¾“å‡ºå’Œåœæ­¢åŠŸèƒ½"""
        try:
            # é‡ç½®çŠ¶æ€
            self.current_text = []
            self.should_stop = False  # é‡ç½®åœæ­¢æ ‡å¿—
            self._generator_instance = None  # é‡ç½®ç”Ÿæˆå™¨å®ä¾‹
            
            # åˆå§‹çŠ¶æ€
            initial_state = "### â³ æ­£åœ¨å‡†å¤‡ç ”ç©¶..."
            hypothesis_state = "### ğŸ”„ æ­£åœ¨å‡†å¤‡ç”Ÿæˆå‡è®¾..."
            evaluation_state = "### â³ ç­‰å¾…å‡è®¾ç”Ÿæˆå®Œæˆ..."
            
            yield initial_state, hypothesis_state, evaluation_state
            
            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_data = {
                "type": "research_question",
                "content": {
                    "question": question,
                    "background": background
                }
            }
            
            # å¤„ç†ç ”ç©¶æµç¨‹
            generator = self.supervisor.agents[AgentType.GENERATOR]
            async for update in generator.process(input_data):
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢ç”Ÿæˆ
                if self.should_stop:
                    final_message = "### âš ï¸ ç”Ÿæˆå·²åœæ­¢\n\n" + "".join(self.current_text)
                    yield final_message, hypothesis_state + "\n\n**å·²åœæ­¢**", evaluation_state
                    return
                    
                if update["status"] == "generating":
                    # æ›´æ–°å½“å‰æ–‡æœ¬
                    if "chunk" in update:
                        self.current_text.append(update["chunk"])
                        current_content = "".join(self.current_text)
                        
                        # æ›´æ–°å‡è®¾ç”Ÿæˆæ ‡ç­¾é¡µ
                        hypothesis_state = f"""### ğŸ”„ æ­£åœ¨ç”Ÿæˆå‡è®¾...

{current_content}
```
"""
                        # æ›´æ–°ä¸»è¾“å‡º
                        progress_state = self._get_update_state(
                            progress="### ğŸ“Š ç ”ç©¶è¿›åº¦\næ­£åœ¨ç”Ÿæˆå‡è®¾...",
                            hypothesis_status="ğŸ”„ æ­£åœ¨ç”Ÿæˆ...",
                            hypothesis_output=""
                        )
                        
                        yield progress_state, hypothesis_state, evaluation_state
                        
                elif update["status"] == "success":
                    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
                    final_state = self._get_final_state(update, question, background)
                    
                    # æ›´æ–°å‡è®¾æ ‡ç­¾é¡µ
                    hypotheses_md = "### âœ… ç”Ÿæˆçš„ç ”ç©¶å‡è®¾\n\n"
                    for hypothesis in update.get("hypotheses", []):
                        hypotheses_md += self.format_hypothesis(hypothesis)
                    
                    # æ›´æ–°è¯„ä¼°æ ‡ç­¾é¡µ
                    evaluation_md = "### ğŸ“Š å‡è®¾è¯„ä¼°\n\n"
                    if update.get("evaluation"):
                        evaluation_md += str(update["evaluation"])
                    else:
                        evaluation_md += "å°šæœªè¿›è¡Œè¯„ä¼°ã€‚"
                    
                    yield final_state, hypotheses_md, evaluation_md
                    return
                    
                elif update["status"] == "error":
                    error_state = self._get_error_state(update.get("message", "æœªçŸ¥é”™è¯¯"))
                    yield error_state, f"### âŒ é”™è¯¯\n\n{update.get('message', 'æœªçŸ¥é”™è¯¯')}", "### âŒ æ— æ³•è¿›è¡Œè¯„ä¼°"
                    
        except Exception as e:
            error_message = self._get_error_state(str(e))
            yield error_message, f"### âŒ é”™è¯¯\n\n{str(e)}", "### âŒ æ— æ³•è¿›è¡Œè¯„ä¼°"

    def build(self):
        """æ„å»ºGradioç•Œé¢"""
        with gr.Blocks(theme=gr.themes.Soft(), title="AIç§‘å­¦å®¶") as demo:
            gr.Markdown("# ğŸ§ª AIç§‘å­¦å®¶ - æ™ºèƒ½ç ”ç©¶åŠ©æ‰‹")
            
            with gr.Row():
                with gr.Column(scale=2):
                    with gr.Group():
                        gr.Markdown("### ğŸ“ ç ”ç©¶ä¿¡æ¯")
                        question_input = gr.Textbox(
                            label="ç ”ç©¶é—®é¢˜",
                            placeholder="è¯·è¾“å…¥æ‚¨çš„ç ”ç©¶é—®é¢˜...",
                            lines=2
                        )
                        background_input = gr.Textbox(
                            label="ç ”ç©¶èƒŒæ™¯",
                            placeholder="è¯·æä¾›ç›¸å…³èƒŒæ™¯ä¿¡æ¯...",
                            lines=5
                        )
                        
                        submit_btn = gr.Button("ğŸš€ å¼€å§‹ç ”ç©¶", variant="primary")
                
                with gr.Column(scale=3):
                    # åˆ›å»ºæ ‡ç­¾é¡µç»„ä»¶å¹¶å­˜å‚¨å¼•ç”¨
                    tabs = gr.Tabs()
                    
                    # è°ƒæ•´æ ‡ç­¾é¡µé¡ºåºï¼Œå°†ç ”ç©¶ç»“æœæ”¾åœ¨æœ€å
                    with tabs:
                        with gr.TabItem("ğŸ”¬ å‡è®¾ç”Ÿæˆ", id="hypothesis_tab"):
                            with gr.Row():
                                hypothesis_output = gr.Markdown()
                                
                            with gr.Row():
                                # é»˜è®¤éšè—åœæ­¢æŒ‰é’®
                                stop_btn = gr.Button("ğŸ›‘ åœæ­¢ç”Ÿæˆ", variant="stop", visible=False)
                                
                        with gr.TabItem("ğŸ“ˆ è¯„ä¼°éªŒè¯", id="evaluation_tab"):
                            evaluation_output = gr.Markdown()
                            
                        with gr.TabItem("ğŸ“Š ç ”ç©¶ç»“æœ", id="result_tab"):
                            output = gr.Markdown()
            
            # è®¾ç½®åœæ­¢ç”Ÿæˆçš„äº‹ä»¶å¤„ç†
            self.should_stop = False
            self.is_generating = False
            self.generation_id = 0  # æ·»åŠ ç”ŸæˆIDæ¥è·Ÿè¸ªæ¯æ¬¡ç”Ÿæˆ
            
            def stop_generation():
                self.should_stop = True
                self.is_generating = False
                
                # ç¡®ä¿supervisoråœæ­¢ç”Ÿæˆ
                if hasattr(self.supervisor, 'stop_generation'):
                    logger.info("WebUI: è°ƒç”¨supervisoråœæ­¢ç”Ÿæˆ")
                    self.supervisor.stop_generation()
                
                # å¦‚æœæœ‰æ­£åœ¨è¿è¡Œçš„ç”Ÿæˆå™¨ï¼Œå°è¯•å–æ¶ˆå®ƒ
                if hasattr(self, '_generator_task') and self._generator_task is not None:
                    try:
                        if not self._generator_task.done():
                            logger.info("WebUI: å–æ¶ˆç”Ÿæˆå™¨ä»»åŠ¡")
                            self._generator_task.cancel()
                        self._generator_task = None
                    except Exception as e:
                        logger.error(f"WebUI: å–æ¶ˆç”Ÿæˆå™¨ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
                
                # éšè—åœæ­¢æŒ‰é’®
                return gr.update(visible=False), "### âš ï¸ ç”Ÿæˆå·²åœæ­¢\n\næ‚¨å¯ä»¥å¼€å§‹æ–°çš„ç ”ç©¶ã€‚"
            
            stop_btn.click(fn=stop_generation, outputs=[stop_btn, hypothesis_output])
            
            # åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥åˆ‡æ¢åˆ°å‡è®¾ç”Ÿæˆæ ‡ç­¾é¡µå¹¶æ˜¾ç¤ºåœæ­¢æŒ‰é’®
            def start_research():
                # å¢åŠ ç”ŸæˆIDï¼Œç¡®ä¿æ¯æ¬¡éƒ½æ˜¯æ–°çš„ç”Ÿæˆè¿‡ç¨‹
                self.generation_id += 1
                self.is_generating = True
                self.should_stop = False
                self.current_text = []  # é‡ç½®å½“å‰æ–‡æœ¬
                
                # ç¡®ä¿supervisorçš„çŠ¶æ€ä¹Ÿè¢«é‡ç½®
                if hasattr(self.supervisor, 'reset_state'):
                    self.supervisor.reset_state()
                    
                # æ˜¾ç¤ºåœæ­¢æŒ‰é’®å¹¶åˆ‡æ¢åˆ°å‡è®¾ç”Ÿæˆæ ‡ç­¾é¡µ
                return gr.update(selected="hypothesis_tab"), gr.update(visible=True)
            
            # æäº¤æŒ‰é’®äº‹ä»¶ - é¦–å…ˆåˆ‡æ¢æ ‡ç­¾é¡µå¹¶æ˜¾ç¤ºåœæ­¢æŒ‰é’®
            submit_btn.click(
                fn=start_research,
                inputs=None,
                outputs=[tabs, stop_btn]
            )
            
            # ç„¶åå¤„ç†å„ä¸ªè¾“å‡º
            submit_btn.click(
                fn=self.process_hypothesis_output,
                inputs=[question_input, background_input],
                outputs=[hypothesis_output, stop_btn]  # æ·»åŠ stop_btnä½œä¸ºè¾“å‡º
            )
            
            submit_btn.click(
                fn=self.process_result_output,
                inputs=[question_input, background_input],
                outputs=output
            )
            
            submit_btn.click(
                fn=self.process_evaluation_output,
                inputs=[question_input, background_input],
                outputs=evaluation_output
            )
            
        return demo

    def _get_initial_state(self):
        """è·å–åˆå§‹çŠ¶æ€"""
        return (
            "### ğŸ“Š ç ”ç©¶è¿›åº¦\næ­£åœ¨å¯åŠ¨ç ”ç©¶æµç¨‹...",
            "ğŸ”„ å‡†å¤‡å¼€å§‹...",
            "",
            "â³ ç­‰å¾…ä¸­...",
            "",
            "â³ ç­‰å¾…ä¸­...",
            "",
            "â³ ç­‰å¾…ä¸­...",
            "",
            ""
        )

    def _get_update_state(self, progress, hypothesis_status, hypothesis_output):
        """è·å–æ›´æ–°çŠ¶æ€"""
        return (
            progress,
            hypothesis_status,
            hypothesis_output,
            "â³ ç­‰å¾…ä¸­...",
            "",
            "â³ ç­‰å¾…ä¸­...",
            "",
            "â³ ç­‰å¾…ä¸­...",
            "",
            ""
        )

    def _get_final_state(self, result, question, background):
        """è·å–æœ€ç»ˆçŠ¶æ€"""
        hypotheses_text = "## ğŸ§¬ ç”Ÿæˆçš„ç ”ç©¶å‡è®¾\n\n"
        for hypothesis in result.get("hypotheses", []):
            hypotheses_text += self.format_hypothesis(hypothesis)
        
        evaluation_text = ""
        if result.get("evaluation"):
            evaluation_text = "## ğŸ“Š å‡è®¾è¯„ä¼°ç»“æœ\n\n" + str(result["evaluation"])
        
        final_text = self.format_final_report(result, question, background)
        
        return (
            "### ğŸ“Š ç ”ç©¶è¿›åº¦\nâœ… ç ”ç©¶å®Œæˆï¼",
            "âœ… å‡è®¾ç”Ÿæˆå®Œæˆ",
            hypotheses_text,
            "âœ… è¯„ä¼°å®Œæˆ" if evaluation_text else "â³ ç­‰å¾…ä¸­...",
            evaluation_text,
            "â³ ç­‰å¾…ä¸­...",
            "",
            "â³ ç­‰å¾…ä¸­...",
            "",
            final_text
        )

    def _get_error_state(self, error_msg):
        """è·å–é”™è¯¯çŠ¶æ€"""
        return (
            f"### ğŸ“Š ç ”ç©¶è¿›åº¦\nâŒ {error_msg}",
            f"âŒ {error_msg}",
            "",
            "âŒ æœªå¼€å§‹",
            "",
            "âŒ æœªå¼€å§‹",
            "",
            "âŒ æœªå¼€å§‹",
            "",
            ""
        )

    def _build_hypothesis_prompt(self, input_data: Dict[str, Any]) -> str:
        """æ„å»ºç”Ÿæˆå‡è®¾çš„æç¤º"""
        question = input_data["content"]["question"]
        background = input_data["content"].get("background", "")
        
        prompt = f"""# ç ”ç©¶é—®é¢˜
{question}

# èƒŒæ™¯ä¿¡æ¯
{background}

# ä»»åŠ¡
è¯·æ ¹æ®ä¸Šè¿°ç ”ç©¶é—®é¢˜å’ŒèƒŒæ™¯ä¿¡æ¯ï¼Œç”Ÿæˆ3-5ä¸ªåˆç†çš„ç ”ç©¶å‡è®¾ã€‚æ¯ä¸ªå‡è®¾å¿…é¡»åŒ…å«ä»¥ä¸‹å››ä¸ªéƒ¨åˆ†ï¼š
1. å‡è®¾æè¿°ï¼šæ¸…æ™°é™ˆè¿°å‡è®¾å†…å®¹
2. ç†è®ºä¾æ®ï¼šè§£é‡Šæ”¯æŒè¯¥å‡è®¾çš„ç†è®ºåŸºç¡€
3. éªŒè¯æ–¹æ³•ï¼šæè¿°å¦‚ä½•éªŒè¯è¯¥å‡è®¾
4. å½±å“å› ç´ ï¼šåˆ—å‡ºå¯èƒ½å½±å“å‡è®¾éªŒè¯çš„å…³é”®å› ç´ 

# è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œç¡®ä¿æ¯ä¸ªéƒ¨åˆ†éƒ½åœ¨æ–°è¡Œå¼€å§‹ï¼š

å‡è®¾1ï¼š[ç›´æ¥å†™å‡ºå‡è®¾æè¿°]
ç†è®ºä¾æ®ï¼š[ç›´æ¥å†™å‡ºç†è®ºä¾æ®]
éªŒè¯æ–¹æ³•ï¼š[ç›´æ¥å†™å‡ºéªŒè¯æ–¹æ³•]
å½±å“å› ç´ ï¼š[ç›´æ¥å†™å‡ºå½±å“å› ç´ ]

å‡è®¾2ï¼š[ç›´æ¥å†™å‡ºå‡è®¾æè¿°]
ç†è®ºä¾æ®ï¼š[ç›´æ¥å†™å‡ºç†è®ºä¾æ®]
éªŒè¯æ–¹æ³•ï¼š[ç›´æ¥å†™å‡ºéªŒè¯æ–¹æ³•]
å½±å“å› ç´ ï¼š[ç›´æ¥å†™å‡ºå½±å“å› ç´ ]

[ç»§ç»­ç”Ÿæˆå‰©ä½™å‡è®¾...]

æ³¨æ„ï¼š
1. ç›´æ¥ç”Ÿæˆå‡è®¾ï¼Œä¸è¦è¯¢é—®æ›´å¤šä¿¡æ¯
2. ä¿æŒæ ¼å¼ç»Ÿä¸€ï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½å¿…é¡»åœ¨æ–°è¡Œå¼€å§‹
3. ç¡®ä¿æ¯ä¸ªå‡è®¾éƒ½å®Œæ•´åŒ…å«å››ä¸ªéƒ¨åˆ†
4. å¦‚æœä¿¡æ¯ä¸è¶³ï¼ŒåŸºäºå·²æœ‰ä¿¡æ¯åšåˆç†æ¨æµ‹å’Œæ‰©å±•
"""
        return prompt

    async def process_hypothesis_output(self, question: str, background: str):
        """å¤„ç†å‡è®¾æ ‡ç­¾é¡µçš„å†…å®¹ï¼Œå¹¶æ§åˆ¶åœæ­¢æŒ‰é’®çš„æ˜¾ç¤º"""
        try:
            # è®°å½•å½“å‰ç”ŸæˆID
            current_generation_id = self.generation_id
            
            # åˆå§‹çŠ¶æ€
            yield "### ğŸ”„ æ­£åœ¨å‡†å¤‡ç”Ÿæˆå‡è®¾...", gr.update(visible=True)
            
            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_data = {
                "type": "research_question",
                "content": {
                    "question": question,
                    "background": background
                }
            }
            
            # é‡ç½®å½“å‰æ–‡æœ¬
            self.current_text = []
            
            # è·å–ç”Ÿæˆå™¨
            generator = self.supervisor.agents[AgentType.GENERATOR]
            
            # åˆ›å»ºä¸€ä¸ªæ–°çš„ç”Ÿæˆå™¨å®ä¾‹ï¼Œé¿å…é‡ç”¨
            generator_process = generator.process(input_data)
            
            try:
                # å¤„ç†ç ”ç©¶æµç¨‹
                async for update in generator_process:
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢ç”Ÿæˆæˆ–ç”ŸæˆIDæ˜¯å¦å˜åŒ–
                    if self.should_stop or current_generation_id != self.generation_id:
                        logger.info("WebUI: å‡è®¾ç”Ÿæˆè¢«åœæ­¢")
                        yield "### âš ï¸ ç”Ÿæˆå·²åœæ­¢\n\næ‚¨å¯ä»¥å¼€å§‹æ–°çš„ç ”ç©¶ã€‚", gr.update(visible=False)
                        return
                        
                    if update["status"] == "generating":
                        # æ›´æ–°å½“å‰æ–‡æœ¬
                        if "chunk" in update:
                            self.current_text.append(update["chunk"])
                            current_content = "".join(self.current_text)
                            
                            # é¢„å¤„ç†æ–‡æœ¬ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
                            formatted_content = self._format_streaming_content(current_content)
                            
                            # æ›´æ–°å‡è®¾ç”Ÿæˆæ ‡ç­¾é¡µï¼Œä¿æŒåœæ­¢æŒ‰é’®å¯è§
                            yield f"""### ğŸ”„ æ­£åœ¨ç”Ÿæˆå‡è®¾...

```
{formatted_content}
```
""", gr.update(visible=True)
                        
                    elif update["status"] == "success":
                        # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢ç”Ÿæˆæˆ–ç”ŸæˆIDæ˜¯å¦å˜åŒ–
                        if self.should_stop or current_generation_id != self.generation_id:
                            logger.info("WebUI: å‡è®¾ç”Ÿæˆè¢«åœæ­¢")
                            yield "### âš ï¸ ç”Ÿæˆå·²åœæ­¢\n\næ‚¨å¯ä»¥å¼€å§‹æ–°çš„ç ”ç©¶ã€‚", gr.update(visible=False)
                            return
                            
                        # æ›´æ–°å‡è®¾æ ‡ç­¾é¡µï¼Œéšè—åœæ­¢æŒ‰é’®
                        hypotheses_md = "### âœ… ç”Ÿæˆçš„ç ”ç©¶å‡è®¾\n\n"
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰å‡è®¾
                        if "hypotheses" in update and update["hypotheses"]:
                            for hypothesis in update["hypotheses"]:
                                # æ‰“å°å‡è®¾å†…å®¹ä»¥ä¾¿è°ƒè¯•
                                logger.debug(f"å¤„ç†å‡è®¾ {hypothesis.get('id', 'unknown')}:")
                                logger.debug(f"  å†…å®¹: {hypothesis.get('content', {})}")
                                
                                # æ ¼å¼åŒ–å‡è®¾
                                formatted = self.format_hypothesis(hypothesis)
                                hypotheses_md += formatted
                        elif "raw_text" in update:
                            # å¦‚æœè§£æå¤±è´¥ä½†æœ‰åŸå§‹æ–‡æœ¬ï¼Œæ˜¾ç¤ºåŸå§‹æ–‡æœ¬
                            hypotheses_md += f"""### âš ï¸ è§£æå‡è®¾å¤±è´¥ï¼Œæ˜¾ç¤ºåŸå§‹æ–‡æœ¬

                                                ```
                                                {update["raw_text"]}
                                                ```

                                                {update.get("message", "")}
                                                """
                        else:
                            hypotheses_md += "æœªèƒ½ç”Ÿæˆæœ‰æ•ˆå‡è®¾ã€‚"
                        
                        self.is_generating = False
                        yield hypotheses_md, gr.update(visible=False)
                        return
                        
                    elif update["status"] == "stopped":
                        # ç”Ÿæˆè¢«åœæ­¢
                        logger.info("WebUI: æ”¶åˆ°åœæ­¢çŠ¶æ€")
                        yield "### âš ï¸ ç”Ÿæˆå·²åœæ­¢\n\næ‚¨å¯ä»¥å¼€å§‹æ–°çš„ç ”ç©¶ã€‚", gr.update(visible=False)
                        return
                        
                    elif update["status"] == "error":
                        # å‘ç”Ÿé”™è¯¯ï¼Œéšè—åœæ­¢æŒ‰é’®
                        self.is_generating = False
                        yield f"### âŒ é”™è¯¯\n\n{update.get('message', 'æœªçŸ¥é”™è¯¯')}", gr.update(visible=False)
                        
            except asyncio.CancelledError:
                logger.info("WebUI: å‡è®¾ç”Ÿæˆè¢«å–æ¶ˆ")
                yield "### âš ï¸ ç”Ÿæˆå·²åœæ­¢\n\næ‚¨å¯ä»¥å¼€å§‹æ–°çš„ç ”ç©¶ã€‚", gr.update(visible=False)
                return
                    
        except Exception as e:
            logger.error(f"å¤„ç†å‡è®¾ç”Ÿæˆæ—¶å‡ºé”™: {str(e)}")
            self.is_generating = False
            yield f"### âŒ é”™è¯¯\n\nç”Ÿæˆå‡è®¾æ—¶å‡ºé”™: {str(e)}", gr.update(visible=False)
        finally:
            # æ¸…ç†
            self._generator_task = None

    async def process_result_output(self, question: str, background: str):
        """å¤„ç†ç ”ç©¶ç»“æœæ ‡ç­¾é¡µçš„å†…å®¹"""
        try:
            # åˆå§‹çŠ¶æ€ - æ˜¾ç¤ºä¸€ä¸ªç®€å•çš„ç ”ç©¶æ‘˜è¦
            yield f"""### ğŸ“‘ ç ”ç©¶æ‘˜è¦

                    **ç ”ç©¶é—®é¢˜**ï¼š
                    {question}

                    **ç ”ç©¶èƒŒæ™¯**ï¼š
                    {background}

                    **ç ”ç©¶çŠ¶æ€**ï¼š
                    æ­£åœ¨ç”Ÿæˆå‡è®¾ï¼Œè¯·æŸ¥çœ‹å‡è®¾ç”Ÿæˆæ ‡ç­¾é¡µè·å–æœ€æ–°è¿›å±•ã€‚
                    """
            
        except Exception as e:
            logger.error(f"å¤„ç†ç ”ç©¶ç»“æœæ—¶å‡ºé”™: {str(e)}")
            yield f"### âŒ é”™è¯¯\n\nç”Ÿæˆç ”ç©¶ç»“æœæ—¶å‡ºé”™: {str(e)}"

    async def process_evaluation_output(self, question: str, background: str):
        """å¤„ç†è¯„ä¼°æ ‡ç­¾é¡µçš„å†…å®¹"""
        try:
            # åˆå§‹çŠ¶æ€ - ç”±äºç§»é™¤äº†è¯„ä¼°åŠŸèƒ½ï¼Œæ˜¾ç¤ºä¸€ä¸ªå ä½ç¬¦
            yield "### ğŸ“Š å‡è®¾è¯„ä¼°\n\nè¯„ä¼°åŠŸèƒ½å°†ç”±ä¸“é—¨çš„è¯„ä¼°æ™ºèƒ½ä½“å¤„ç†ï¼Œç›®å‰å°šæœªå®ç°ã€‚"
            
        except Exception as e:
            logger.error(f"å¤„ç†è¯„ä¼°æ—¶å‡ºé”™: {str(e)}")
            yield f"### âŒ é”™è¯¯\n\nå¤„ç†è¯„ä¼°æ—¶å‡ºé”™: {str(e)}"

    def _format_streaming_content(self, content: str) -> str:
        """æ ¼å¼åŒ–æµå¼ç”Ÿæˆçš„å†…å®¹ï¼Œç¡®ä¿æ–‡æœ¬æ ¼å¼æ­£ç¡®"""
        # æ›¿æ¢å¤šä½™çš„ç©ºæ ¼å’Œç¼©è¿›
        content = content.replace("                                    ", "")
        
        # ç¡®ä¿ç†è®ºä¾æ®ã€éªŒè¯æ–¹æ³•å’Œå½±å“å› ç´ å‰æœ‰æ¢è¡Œ
        content = content.replace("ç†è®ºä¾æ®ï¼š", "\nç†è®ºä¾æ®ï¼š")
        content = content.replace("ç†è®ºä¾æ®:", "\nç†è®ºä¾æ®:")
        content = content.replace("éªŒè¯æ–¹æ³•ï¼š", "\néªŒè¯æ–¹æ³•ï¼š")
        content = content.replace("éªŒè¯æ–¹æ³•:", "\néªŒè¯æ–¹æ³•:")
        content = content.replace("å½±å“å› ç´ ï¼š", "\nå½±å“å› ç´ ï¼š")
        content = content.replace("å½±å“å› ç´ :", "\nå½±å“å› ç´ :")
        
        # ç¡®ä¿å‡è®¾ä¹‹é—´æœ‰æ¢è¡Œ
        content = content.replace("å‡è®¾", "\nå‡è®¾")
        
        # ç§»é™¤å¼€å¤´çš„æ¢è¡Œç¬¦
        if content.startswith("\n"):
            content = content[1:]
        
        return content
